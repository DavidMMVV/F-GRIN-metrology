{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c40e24",
   "metadata": {},
   "source": [
    "## Object creation example\n",
    "\n",
    "In this notebook, an exaple for creating an object with a F-GRIN will be given. First I define the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9618284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import io\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}.\")\n",
    "\n",
    "def FT(x):\n",
    "    return torch.fft.fftshift(torch.fft.fft2(x))\n",
    "\n",
    "def iFT(x):\n",
    "    return torch.fft.ifft2(torch.fft.ifftshift(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282a8be",
   "metadata": {},
   "source": [
    "Now I create the functions for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_z_scan_gif(volume: torch.Tensor, \n",
    "                    cmap: str = 'gray', \n",
    "                    duration: float = 0.1, \n",
    "                    pix_size: float = 1e-6):\n",
    "    \"\"\"\n",
    "    Displays a loop showing all the slices of a volumetric object.\n",
    "\n",
    "    Args:\n",
    "        volume (_type_): _description_\n",
    "        cmap (str, optional): _description_. Defaults to 'gray'.\n",
    "        duration (float, optional): _description_. Defaults to 0.1.\n",
    "        pix_size (_type_, optional): _description_. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    volume = volume.cpu().numpy() # type: ignore\n",
    "    D = volume.shape[0]\n",
    "    frames = []\n",
    "\n",
    "    vmin = np.min(volume)\n",
    "    vmax = np.max(volume)\n",
    "\n",
    "    for z in range(D):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4), dpi=80)\n",
    "        im = ax.imshow(volume[z], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax.axis('off')\n",
    "\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "        z_pos = (z - D / 2) * pix_size * 1e6\n",
    "        label = f\"Z = {z_pos:.2f} µm\"\n",
    "\n",
    "        ax.text(0.05, 0.95, label, transform=ax.transAxes,\n",
    "                fontsize=10, color='white', ha='left', va='top',\n",
    "                bbox=dict(facecolor='black', alpha=0.5, boxstyle='round'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        buf.seek(0)\n",
    "        frames.append(imageio.v3.imread(buf))\n",
    "        buf.close()\n",
    "\n",
    "    # Create looping GIF\n",
    "    gif_bytes = io.BytesIO()\n",
    "    imageio.mimsave(gif_bytes, frames, format='gif', duration=duration, loop=0) # type: ignore\n",
    "    gif_bytes.seek(0)\n",
    "\n",
    "    display(Image(data=gif_bytes.read(), format='gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a7db9",
   "metadata": {},
   "source": [
    "I define the pseudo F-GRIN sample (ideally should be defined as shown by the article writen by David H Lippman et al. named [Freeform gradient-index media: a new frontier in freeform optics](https://pubmed-ncbi-nlm-nih-gov.tudelft.idm.oclc.org/34809097/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_size = 0.1e-6\n",
    "D, H, W = (64,256,256)\n",
    "\n",
    "Z, Y, X = torch.meshgrid(\n",
    "    pix_size*(torch.arange(D, device=device) - D/2),\n",
    "    pix_size*(torch.arange(H, device=device) - H/2),\n",
    "    pix_size*(torch.arange(W, device=device) - W/2),\n",
    "    indexing='ij'\n",
    ")\n",
    "\n",
    "λ = 535e-9\n",
    "rad = 3e-6\n",
    "n_a = 1.5\n",
    "dn = 0.005\n",
    "\n",
    "sample_3D = (X**2 + Y**2 + Z**2)**3 * ((X**2 + Y**2 + Z**2)<rad**2)\n",
    "#sample_3D = 4 * ((X**2 + Y**2 ))\n",
    "sample_3D -= sample_3D.min()\n",
    "sample_3D /= sample_3D.max()\n",
    "sample_3D = sample_3D * dn + n_a\n",
    "\n",
    "show_z_scan_gif(sample_3D, cmap='plasma', duration=0.1, pix_size=pix_size)\n",
    "plt.figure()\n",
    "plt.imshow(sample_3D.sum(axis=0).cpu().numpy(), cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ae470",
   "metadata": {},
   "source": [
    "I create the functions and classes to perform the propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import Shape\n",
    "\n",
    "\n",
    "class Simparams:\n",
    "    \"\"\"\n",
    "    Class for storing the most used variables during the simulation and return the coordinates.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 pix_size : float,\n",
    "                 shape : tuple[int, int, int],\n",
    "                 λ : float,\n",
    "                 device : str,\n",
    "                 n_0 : float = 1) -> None:\n",
    "        self.pix_size = pix_size\n",
    "        self.shape = shape\n",
    "        self.λ = λ\n",
    "        self.device = device\n",
    "        self.n_0 = n_0\n",
    "        self.D, self.H, self.W = shape \n",
    "    \n",
    "    def real_coord(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.pix_size * (torch.arange(self.W, device=self.device) - self.W / 2) \n",
    "        y = self.pix_size * (-torch.arange(self.H, device=self.device) + self.H / 2) \n",
    "        Y, X = torch.meshgrid(y,x, indexing='ij')\n",
    "        return Y, X\n",
    "    \n",
    "    def f_coord(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        f_pix_size = (1 / (self.H * self.pix_size), 1 / (self.W * self.pix_size))\n",
    "        fx = f_pix_size[1] * (torch.arange(self.W, device=self.device) - self.W / 2) \n",
    "        fy = f_pix_size[0] * (-torch.arange(self.H, device=self.device) + self.H / 2) \n",
    "        FY, FX = torch.meshgrid(fy,fx, indexing='ij')\n",
    "        return FY, FX\n",
    "\n",
    "\n",
    "def as_propagator(FY : torch.Tensor,\n",
    "                  FX : torch.Tensor,\n",
    "                  n : float | complex | torch.Tensor,\n",
    "                  z: float,\n",
    "                  λ : float\n",
    "                  ) -> torch.Tensor:\n",
    "    return torch.exp(2j * torch.pi * z * \n",
    "                     torch.sqrt(((n / λ)**2 - FX**2 - FY**2).to(torch.complex128)))\n",
    "\n",
    "\n",
    "def propagation(u_i: torch.Tensor,\n",
    "                vol_n: torch.Tensor,\n",
    "                propagator: Callable,\n",
    "                sim_params: Simparams,\n",
    "                ) -> torch.Tensor:\n",
    "\n",
    "    FY, FX = sim_params.real_coord()\n",
    "    u_o = u_i.detach().clone()\n",
    "    \n",
    "    phase_vol = torch.exp(2j * torch.pi * (sim_params.n_0-vol_n) /  λ)\n",
    "    \n",
    "    prop_fact = propagator(FY, FX, sim_params.n_0, sim_params.pix_size/2, sim_params.λ)\n",
    "    for i in range(D):\n",
    "        u_o = iFT(FT(u_o) * prop_fact)\n",
    "        u_o *= phase_vol[i]\n",
    "        u_o = iFT(FT(u_o) * prop_fact)\n",
    "    return u_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee7383",
   "metadata": {},
   "source": [
    "Now we obtain the real output wave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from fgrinmet.essentials.representation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sim_params = Simparams(pix_size, (D, H, W), λ, device, n_a)\n",
    "\n",
    "\n",
    "#Y, X = sim_params.real_coord()\n",
    "print(Y.device)\n",
    "#gauss = torch.exp(-X*X-Y*Y).detach().cpu().numpy()\n",
    "#u_i = torch.Tensor(gauss, device=device, dtype=torch.complex128)\n",
    "#u_i = torch.exp(-X*X-Y*Y).detach()\n",
    "u_i =  torch.ones((H, W), device=device, dtype=torch.complex128)\n",
    "u_o_real = propagation(u_i, sample_3D, as_propagator, sim_params)\n",
    "\n",
    "show_complex(u_o_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ac91a",
   "metadata": {},
   "source": [
    "And finally we apply the reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_mse_loss(input, target):\n",
    "    return ((input.real - target.real)**2 + (input.imag - target.imag)**2).mean()\n",
    "\n",
    "sample_guess = torch.full((D,H,W), fill_value=sim_params.n_0, device=device, requires_grad=True)\n",
    "loss_f = complex_mse_loss\n",
    "\n",
    "num_steps = 100\n",
    "optimizer = torch.optim.Adam([sample_guess], lr=1e-3)\n",
    "losses = []\n",
    "with tqdm(range(num_steps), desc=\"Optimizing\") as pbar:\n",
    "    for step in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        u_o_guess = propagation(u_i, sample_guess, as_propagator, sim_params)\n",
    "        loss = complex_mse_loss(u_o_guess, u_o_real)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm postfix with current loss\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.6e}\")\n",
    "\n",
    "        losses.append(loss.detach().cpu().float())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iter\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "sample_guess_show = sample_guess.detach()\n",
    "show_z_scan_gif(sample_guess_show, cmap='plasma', duration=0.1, pix_size=pix_size)\n",
    "plt.figure()\n",
    "plt.imshow(sample_guess_show.sum(axis=0).cpu().numpy(), cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edf1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f-grin-metrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
